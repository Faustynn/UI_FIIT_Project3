[2024-12-02 01:19:16,265] Train: xor (1 hidden layer) ReLu
[2024-12-02 01:19:16,266] Epoch 0, Loss: 0.4908523352629769
[2024-12-02 01:19:16,278] Epoch 50, Loss: 0.23708566996228608
[2024-12-02 01:19:16,295] Epoch 100, Loss: 0.16978600747359995
[2024-12-02 01:19:16,307] Epoch 150, Loss: 0.03661203509697997
[2024-12-02 01:19:16,319] Epoch 200, Loss: 1.926538679311998e-11
[2024-12-02 01:19:16,324] Epoch 250, Loss: 1.531181667015596e-20
[2024-12-02 01:19:16,335] Epoch 300, Loss: 2.1477970739806454e-30
[2024-12-02 01:19:16,357] Epoch 350, Loss: 0.0
[2024-12-02 01:19:16,362] Early stopping at epoch 362
[2024-12-02 01:19:16,362] Train: xor (1 hidden layer) Tahn
[2024-12-02 01:19:16,363] Epoch 0, Loss: 0.4907352326437151
[2024-12-02 01:19:16,386] Epoch 50, Loss: 0.2529748968373269
[2024-12-02 01:19:16,393] Early stopping at epoch 73
[2024-12-02 01:19:16,394] Train: XOR (2 hidden layers) Tanh
[2024-12-02 01:19:16,395] Epoch 0, Loss: 0.4909280462796399
[2024-12-02 01:19:16,410] Epoch 50, Loss: 0.25296944374428426
[2024-12-02 01:19:16,417] Early stopping at epoch 73
[2024-12-02 01:19:16,417] Train: XOR (2 hidden layers) ReLu
[2024-12-02 01:19:16,418] Epoch 0, Loss: 0.5000996266547234
[2024-12-02 01:19:16,434] Epoch 50, Loss: 0.2551289119425127
[2024-12-02 01:19:16,441] Epoch 100, Loss: 0.2550499716149226
[2024-12-02 01:19:16,458] Epoch 150, Loss: 0.2550499109682498
[2024-12-02 01:19:16,465] Epoch 200, Loss: 0.25504987438803645
[2024-12-02 01:19:16,486] Epoch 250, Loss: 0.25504983750868715
[2024-12-02 01:19:16,495] Epoch 300, Loss: 0.2550498002771683
[2024-12-02 01:19:16,503] Epoch 350, Loss: 0.25504976265688495
[2024-12-02 01:19:16,510] Epoch 400, Loss: 0.2550497245778086
[2024-12-02 01:19:16,519] Epoch 450, Loss: 0.25504968599988836
[2024-12-02 01:19:16,527] Train: xor (1 hidden layer) Sigmoid
[2024-12-02 01:19:16,527] Epoch 0, Loss: 0.25065440299996045
[2024-12-02 01:19:16,532] Epoch 50, Loss: 0.2506572865404335
[2024-12-02 01:19:16,532] Early stopping at epoch 51
[2024-12-02 01:19:16,532] Train: XOR (2 hidden layers) Sigmoid
[2024-12-02 01:19:16,533] Epoch 0, Loss: 0.25065791925111425
[2024-12-02 01:19:16,550] Epoch 50, Loss: 0.2506595232407921
[2024-12-02 01:19:16,551] Early stopping at epoch 51
[2024-12-02 01:19:16,551] Train: xor (1 hidden layer) Mix
[2024-12-02 01:19:16,551] Epoch 0, Loss: 0.25033870217849546
[2024-12-02 01:19:16,559] Epoch 50, Loss: 0.25032935202037093
[2024-12-02 01:19:16,565] Epoch 100, Loss: 0.25032096714344815
[2024-12-02 01:19:16,571] Epoch 150, Loss: 0.25027043320920556
[2024-12-02 01:19:16,576] Epoch 200, Loss: 0.25001577295231076
[2024-12-02 01:19:16,584] Epoch 250, Loss: 0.24869093404565798
[2024-12-02 01:19:16,590] Epoch 300, Loss: 0.24212223716518053
[2024-12-02 01:19:16,596] Epoch 350, Loss: 0.2189259192959352
[2024-12-02 01:19:16,601] Epoch 400, Loss: 0.18743893256521468
[2024-12-02 01:19:16,606] Epoch 450, Loss: 0.1736832909725114
[2024-12-02 01:19:16,611] Train: XOR Custom
[2024-12-02 01:19:16,611] Epoch 0, Loss: 0.25000260688705966
[2024-12-02 01:19:16,618] Epoch 50, Loss: 0.2500026186701565
[2024-12-02 01:19:16,618] Early stopping at epoch 51
[2024-12-02 01:19:16,618] Train: AND (1 layer, momentum)
[2024-12-02 01:19:16,618] Epoch 0, Loss: 0.25072534353465015
[2024-12-02 01:19:16,621] Epoch 50, Loss: 0.14790200545585355
[2024-12-02 01:19:16,624] Epoch 100, Loss: 0.10801706458148923
[2024-12-02 01:19:16,628] Epoch 150, Loss: 0.085319145808653
[2024-12-02 01:19:16,631] Epoch 200, Loss: 0.0704415853350393
[2024-12-02 01:19:16,634] Epoch 250, Loss: 0.059787930970430794
[2024-12-02 01:19:16,637] Epoch 300, Loss: 0.05173675486926843
[2024-12-02 01:19:16,640] Epoch 350, Loss: 0.04543281153503733
[2024-12-02 01:19:16,643] Epoch 400, Loss: 0.040370020152917505
[2024-12-02 01:19:16,647] Epoch 450, Loss: 0.036223991527203195
[2024-12-02 01:19:16,650] Train: AND (2 layer, momentum)
[2024-12-02 01:19:16,650] Epoch 0, Loss: 0.25180555374890345
[2024-12-02 01:19:16,655] Epoch 50, Loss: 0.18671306038406565
[2024-12-02 01:19:16,660] Epoch 100, Loss: 0.18469905121815625
[2024-12-02 01:19:16,665] Epoch 150, Loss: 0.18202712170359148
[2024-12-02 01:19:16,670] Epoch 200, Loss: 0.17813342824747122
[2024-12-02 01:19:16,675] Epoch 250, Loss: 0.1724299835044643
[2024-12-02 01:19:16,680] Epoch 300, Loss: 0.16440551916486557
[2024-12-02 01:19:16,685] Epoch 350, Loss: 0.15394173684427215
[2024-12-02 01:19:16,690] Epoch 400, Loss: 0.1415750392530789
[2024-12-02 01:19:16,695] Epoch 450, Loss: 0.12830734211343198
[2024-12-02 01:19:16,700] Train: ORR (1 layer, momentum)
[2024-12-02 01:19:16,700] Epoch 0, Loss: 0.25244189554627877
[2024-12-02 01:19:16,703] Epoch 50, Loss: 0.10834008911829712
[2024-12-02 01:19:16,706] Epoch 100, Loss: 0.07869060458003814
[2024-12-02 01:19:16,709] Epoch 150, Loss: 0.059651226064738376
[2024-12-02 01:19:16,713] Epoch 200, Loss: 0.047040575757278824
[2024-12-02 01:19:16,716] Epoch 250, Loss: 0.03829228516613208
[2024-12-02 01:19:16,719] Epoch 300, Loss: 0.03197425249958337
[2024-12-02 01:19:16,722] Epoch 350, Loss: 0.02725487460955257
[2024-12-02 01:19:16,725] Epoch 400, Loss: 0.02362811471103496
[2024-12-02 01:19:16,728] Epoch 450, Loss: 0.020773111172286265
[2024-12-02 01:19:16,732] Train: ORR (2 layer, momentum)
[2024-12-02 01:19:16,732] Epoch 0, Loss: 0.2509293047213465
[2024-12-02 01:19:16,737] Epoch 50, Loss: 0.18634828618851385
[2024-12-02 01:19:16,742] Epoch 100, Loss: 0.18462354221735988
[2024-12-02 01:19:16,747] Epoch 150, Loss: 0.182449035896937
[2024-12-02 01:19:16,753] Epoch 200, Loss: 0.17958348499909885
[2024-12-02 01:19:16,758] Epoch 250, Loss: 0.17573602881143333
[2024-12-02 01:19:16,763] Epoch 300, Loss: 0.1705756002571426
[2024-12-02 01:19:16,768] Epoch 350, Loss: 0.16372201030917066
[2024-12-02 01:19:16,774] Epoch 400, Loss: 0.15475906178111223
[2024-12-02 01:19:16,779] Epoch 450, Loss: 0.14330988027857766
